{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "95fe9a0b",
      "metadata": {},
      "source": [
        "# 1. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433c6a37",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "Well_B=pd.read_csv(r'E:\\jupyter\\lost_circulation\\records\\paper-bhyt\\MLR\\data\\Well_B.csv')\n",
        "Well_B.info()\n",
        "# Original data information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fd353d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete missing values\n",
        "# Delete torque values less than 0 (later discovered that torque values are less than 0)\n",
        "Well_B = Well_B[Well_B['扭矩'] >= 0]\n",
        "Well_B=Well_B.dropna()\n",
        "Well_B.reset_index(inplace=True,drop=True) # Reset index and drop the column containing the index\n",
        "Well_B.info()\n",
        "Well_B.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_1.csv',index=False,encoding='utf_8_sig')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faeab1d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform label encoding on object type variables\n",
        "# Well number, well type, formation, lithology, formation structure, and lost circulation status\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def label_encode_columns(input_csv, output_csv, columns_to_encode, mappings_dir):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(input_csv)\n",
        "    \n",
        "    # Create a dictionary to store the LabelEncoder objects for each column\n",
        "    label_encoders = {}\n",
        "    \n",
        "    # Ensure the mappings directory exists\n",
        "    if not os.path.exists(mappings_dir):\n",
        "        os.makedirs(mappings_dir)\n",
        "\n",
        "    # Perform label encoding for specified columns\n",
        "    for column in columns_to_encode:\n",
        "        le = LabelEncoder()\n",
        "        df[column + '_encoded'] = le.fit_transform(df[column])\n",
        "        label_encoders[column] = le\n",
        "        \n",
        "        # Save the original data-encoded mappings after removing duplicates\n",
        "        unique_mappings = pd.DataFrame({\n",
        "            column: le.classes_,\n",
        "            column + '_encoded': range(len(le.classes_))\n",
        "        })\n",
        "        mapping_file = os.path.join(mappings_dir, f'{column}_mappings.csv')\n",
        "        unique_mappings.to_csv(mapping_file, index=False,encoding='utf_8_sig')\n",
        "\n",
        "    # Save the encoded data to a new CSV file\n",
        "    df.to_csv(output_csv, index=False,encoding='utf_8_sig')\n",
        "    \n",
        "    return df, label_encoders\n",
        "\n",
        "# Example usage\n",
        "input_csv = 'E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_1.csv'  # Input CSV file path\n",
        "output_csv = 'E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/output_encoded_label.csv'  # Output CSV file path\n",
        "mappings_dir = 'E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/mappings'  # Directory to save encoding mappings\n",
        "columns_to_encode = ['井号', '井别','层位','岩性','地层构造','漏失情况']  # List of columns to encode\n",
        "\n",
        "df_encoded, encoders = label_encode_columns(input_csv, output_csv, columns_to_encode, mappings_dir)\n",
        "print(df_encoded.head())  # Display the first few rows of encoded data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b604293a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select numeric data for saving (feature names converted to English)\n"
    "df=pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/output_encoded_label.csv')\n",
    "df_1=df[['井号_encoded','井别_encoded','井深','垂深','层位_encoded','岩性_encoded',\n",
    "        '地层构造_encoded','钻压','转速','扭矩','泵压','排量','出口密度','ECD','大钩负荷','机械钻速',\n",
    "        '钻时','DC指数','迟到时间','出口流量','地层压力梯度','地层破裂压力梯度','理论最大排量','排泵比','漏失情况_encoded']]\n",
    "df_1.columns=['WellName','WellType','WellDepth','TVD','Layer','Lithology','FormationStructure','WOB','RPM','TOR','PumpPressure',\n",
    "              'Displacement','Density','ECD','HookLoad','ROP','DrillTime','DC','LagTime','OutletFlow','FormationPressureGradient',\n",
    "              'FormationRupturePressureGradient','TheoreticalMaximumDisplacement','DisPumpRatio','LostCirculation']\n",
    "df_1.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_encoded_label.csv', encoding='utf_8_sig',index=False)\n",
    "df_1.info()#保存编码后的数据并输出数据信息\n",
    "df_2=df_1.describe()\n",
    "print(df_2)\n",
    "df_2.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_encoded_label_describe.csv',encoding='utf_8_sig')\n",
    "#保存并输出数据描述信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965287a9",
   "metadata": {},
   "source": [
    "# anomaly value processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# 创建从蓝色到红色的渐变色\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\"blue_red\", [\"blue\", \"red\"])\n",
    "\n",
    "# 设置绘图参数 \n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 设置字体为加粗，符合SCI论文要求\n",
    "plt.rcParams['font.size'] = 12  # 设置整体字体大小为12，适合大多数论文\n",
    "plt.rcParams['font.weight'] = 'bold'  # 设置整体字体为加粗\n",
    "# 对于轴标签、标题、图例和刻度，可以做单独设置\n",
    "plt.rcParams['axes.titlesize'] = 14  # 轴标题更大\n",
    "plt.rcParams['axes.labelsize'] = 12   # 轴标签略大\n",
    "plt.rcParams['axes.titleweight'] = 'bold'  # 轴标题加粗\n",
    "plt.rcParams['axes.labelweight'] = 'bold'  # 轴标签加粗\n",
    "plt.rcParams['xtick.labelsize'] = 10   # x轴刻度标签稍大\n",
    "plt.rcParams['ytick.labelsize'] = 10   # y轴刻度标签稍大\n",
    "plt.rcParams['legend.fontsize'] = 10   # 图例字体更大\n",
    "plt.rcParams['legend.title_fontsize'] = 12  # 图例标题字体更大\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_encoded_label.csv')\n",
    "\n",
    "# 选择数值型数据\n",
    "feature_columns = ['WellDepth', 'DC', 'FormationPressureGradient', 'FormationRupturePressureGradient',\n",
    "                   'WOB', 'RPM', 'TOR', 'PumpPressure', 'HookLoad', 'ROP',\n",
    "                   'Displacement', 'Density', 'ECD', 'OutletFlow', 'LagTime', 'TheoreticalMaximumDisplacement']\n",
    "data_des = data[feature_columns].describe()\n",
    "data_des.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_raw_des.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 初始化 cleaned_data 为原始数据\n",
    "cleaned_data = data.copy()\n",
    "\n",
    "# 循环处理每个特征列\n",
    "for feature in feature_columns:\n",
    "    # 计算 IQR\n",
    "    Q1 = cleaned_data[feature].quantile(0.25)\n",
    "    Q3 = cleaned_data[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # 定义异常值的上下限\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # 标记异常值\n",
    "    cleaned_data['anomaly'] = ((cleaned_data[feature] < lower_bound) | (cleaned_data[feature] > upper_bound)).astype(int)\n",
    "\n",
    "    # 可视化异常值检测结果（散点图）\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # 绘制正常数据（蓝色）\n",
    "    normal_data = cleaned_data[cleaned_data['anomaly'] == 0]\n",
    "    plt.scatter(normal_data.index, normal_data[feature], color='blue', label='Normal Data', alpha=0.6)\n",
    "\n",
    "    # 绘制异常数据（红色）\n",
    "    anomaly_data = cleaned_data[cleaned_data['anomaly'] == 1]\n",
    "    plt.scatter(anomaly_data.index, anomaly_data[feature], color='red', label='Anomaly Data', alpha=0.6)\n",
    "\n",
    "    # 使用渐变色 cmap 为整个数据集添加颜色\n",
    "    scatter = plt.scatter(cleaned_data.index, cleaned_data[feature], c=cleaned_data['anomaly'], cmap=cmap, alpha=0.6, vmin=0, vmax=1)\n",
    "\n",
    "    plt.title(f'IQR Anomaly Detection for {feature}')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel(feature)\n",
    "    plt.axhline(0, color='grey', lw=1)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 设置颜色条并设置标签\n",
    "    cbar = plt.colorbar(scatter)  # 创建颜色条\n",
    "    cbar.set_label('Anomaly Label (0: Normal, 1: Anomaly)')  # 设置颜色条标签\n",
    "    cbar.set_ticks([0, 1])  # 设置颜色条的刻度\n",
    "    cbar.set_ticklabels(['Normal', 'Anomaly'])  # 设置颜色条的刻度标签\n",
    "    # 调整子图的边距，避免右端多余空白\n",
    "    plt.subplots_adjust(right=1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/IQR/detection_{feature}.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # 去除异常值\n",
    "    cleaned_data = cleaned_data[cleaned_data['anomaly'] == 0]\n",
    "    # 合并原始数据和清理后数据为一个DataFrame\n",
    "    combined_data = pd.DataFrame({\n",
    "        'Original': data[feature],\n",
    "        'Cleaned': cleaned_data[feature].reindex(data.index)  # 保持索引一致\n",
    "    })\n",
    "    # 可视化去除异常值前后的数据分布对比（箱型图）\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=combined_data, palette='pastel')\n",
    "    plt.title(f'Comparison of Original and Cleaned Data for {feature}')\n",
    "    plt.ylabel(feature)\n",
    "    plt.xticks(ticks=[0, 1], labels=['Original', 'Cleaned'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/IQR/comparison_{feature}.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # 清理临时列\n",
    "    cleaned_data.drop(columns=['anomaly'], inplace=True)\n",
    "\n",
    "# 保存去除异常值后的数据\n",
    "cleaned_data.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_IQR.csv', encoding='utf-8-sig', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取处理异常值后的数据描述信息\n",
    "IQR=pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_IQR.csv')\n",
    "IQR_des=IQR.describe()\n",
    "print(IQR_des)\n",
    "IQR_des.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_IQR_des.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85442317",
   "metadata": {},
   "source": [
    "# 2、feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8983d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 设置绘图参数 \n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 设置字体为加粗，符合SCI论文要求\n",
    "plt.rcParams['font.size'] = 12  # 设置整体字体大小为12，适合大多数论文\n",
    "plt.rcParams['font.weight'] = 'bold'  # 设置整体字体为加粗\n",
    "# 对于轴标签、标题、图例和刻度，可以做单独设置\n",
    "plt.rcParams['axes.titlesize'] = 14  # 轴标题更大\n",
    "plt.rcParams['axes.labelsize'] = 12   # 轴标签略大\n",
    "plt.rcParams['axes.titleweight'] = 'bold'  # 轴标题加粗\n",
    "plt.rcParams['axes.labelweight'] = 'bold'  # 轴标签加粗\n",
    "plt.rcParams['xtick.labelsize'] = 10   # x轴刻度标签稍大\n",
    "plt.rcParams['ytick.labelsize'] = 10   # y轴刻度标签稍大\n",
    "plt.rcParams['legend.fontsize'] = 10   # 图例字体更大\n",
    "plt.rcParams['legend.title_fontsize'] = 12  # 图例标题字体更大\n",
    "\n",
    "\n",
    "# 1. 数据准备\n",
    "# 从 CSV 文件中导入数据\n",
    "data = pd.read_csv(r'E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_IQR.csv')\n",
    "\n",
    "# 查看数据前几行，确认数据结构\n",
    "print(\"数据预览：\")\n",
    "print(data.head())\n",
    "\n",
    "# 选择特征列和目标标签列\n",
    "# 假设目标列为 '漏失情况'\n",
    "feature_columns = ['WellDepth', 'DC', 'FormationPressureGradient', 'FormationRupturePressureGradient',\n",
    "                   'WOB', 'RPM', 'TOR', 'PumpPressure', 'HookLoad', 'ROP',\n",
    "                   'Displacement', 'Density', 'ECD', 'OutletFlow', 'LagTime', 'TheoreticalMaximumDisplacement']\n",
    "#'WellName','WellType',\n",
    "target_column = 'LostCirculation'\n",
    "\n",
    "# 提取特征和标签\n",
    "X = data[feature_columns]\n",
    "y = data[target_column]\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# 归一化处理\n",
    "scaler = MinMaxScaler()\n",
    "# 只对训练集的特征进行归一化训练，并应用到训练集和测试集\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 2. 随机森林模型\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "rf_accuracy=accuracy_score(y_test, y_pred_rf)\n",
    "print(\"\\n随机森林模型性能:\")\n",
    "print(f\"Accuracy: \",rf_accuracy)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# 3. XGBoost模型\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "#xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "xgb_accuracy=accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"\\nXGBoost模型性能:\")\n",
    "print(f\"Accuracy: \",xgb_accuracy)\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# 4. LightGBM模型\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test_scaled)\n",
    "lgb_accuracy=accuracy_score(y_test, y_pred_lgb)\n",
    "print(\"\\nLightGBM模型性能:\")\n",
    "print(f\"Accuracy: \",lgb_accuracy)\n",
    "print(classification_report(y_test, y_pred_lgb))\n",
    "\n",
    "# 5. 提取各模型的特征重要性\n",
    "# 随机森林\n",
    "rf_importance = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "# XGBoost\n",
    "xgb_importance = pd.Series(xgb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "# LightGBM\n",
    "lgb_importance = pd.Series(lgb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# 6. 将特征重要性保存到 CSV 文件中\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'RandomForest': rf_importance.reindex(X.columns).values,\n",
    "    'XGBoost': xgb_importance.reindex(X.columns).values,\n",
    "    'LightGBM': lgb_importance.reindex(X.columns).values,\n",
    "    'RF_accuracy':accuracy_score(y_test, y_pred_rf),\n",
    "    'XGB_accuracy':accuracy_score(y_test, y_pred_xgb),\n",
    "    'LGBM_accuracy':accuracy_score(y_test, y_pred_lgb)\n",
    "})\n",
    "# 保存为 CSV 文件\n",
    "importance_df.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_feature_importance.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"特征重要性已保存至 'Well_B_feature_importance.csv'\")\n",
    "\n",
    "# 7. 绘制每个模型的特征重要性条形图并分别保存\n",
    "# 7.1 随机森林特征重要性\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=rf_importance.values, y=rf_importance.index, color='skyblue')\n",
    "for index, value in enumerate(rf_importance.values):\n",
    "    plt.text(value, index, f'{value:.2f}', va='center')  # 在条形图上标注数值\n",
    "plt.title(\"Random forest feature importance\")\n",
    "plt.xlabel(\"Importance score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "# 保存图像\n",
    "plt.tight_layout()\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/RF_feature_importance.png', dpi=300)\n",
    "print(\"随机森林特征重要性图已保存为 'RF_feature_importance.png'\")\n",
    "plt.show()\n",
    "\n",
    "# 7.2 XGBoost特征重要性\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=xgb_importance.values, y=xgb_importance.index, color='lightgreen')\n",
    "for index, value in enumerate(xgb_importance.values):\n",
    "    plt.text(value, index, f'{value:.2f}', va='center')\n",
    "plt.title(\"XGBoost feature importance\")\n",
    "plt.xlabel(\"Importance score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "# 保存图像\n",
    "plt.tight_layout()\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/XGB_feature_importance.png', dpi=300)\n",
    "print(\"XGBoost特征重要性图已保存为 'XGB_feature_importance.png'\")\n",
    "plt.show()\n",
    "\n",
    "# 7.3 LightGBM特征重要性\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=lgb_importance.values, y=lgb_importance.index, color='lightcoral')\n",
    "for index, value in enumerate(lgb_importance.values):\n",
    "    plt.text(value, index, f'{value:.2f}', va='center')\n",
    "plt.title(\"LightGBM feature importance\")\n",
    "plt.xlabel(\"Importance score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "# 保存图像\n",
    "plt.tight_layout()\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/LGBM_feature_importance.png', dpi=300)\n",
    "print(\"LightGBM特征重要性图已保存为 'LGBM_feature_importance.png'\")\n",
    "plt.show()\n",
    "\n",
    "# 8. 模型的综合特征重要性\n",
    "# 8.1 计算标准化的特征重要性\n",
    "# 对每个模型的特征重要性进行标准化，使其在 0-1 之间\n",
    "rf_importance_norm = (rf_importance - rf_importance.min()) / (rf_importance.max() - rf_importance.min())\n",
    "xgb_importance_norm = (xgb_importance - xgb_importance.min()) / (xgb_importance.max() - xgb_importance.min())\n",
    "lgb_importance_norm = (lgb_importance - lgb_importance.min()) / (lgb_importance.max() - lgb_importance.min())\n",
    "\n",
    "# 8.2 计算综合特征重要性（可以使用算术平均或几何平均）\n",
    "# 方法一：算术平均\n",
    "#combined_importance = (rf_importance_norm + xgb_importance_norm + lgb_importance_norm) / 3\n",
    "# 方法二：使用 np.power 和 np.prod 计算几何平均\n",
    "#combined_importance = np.power(rf_importance_norm * xgb_importance_norm * lgb_importance_norm, 1/3)\n",
    "#方法三：准确率加权平均\n",
    "# 权重计算（总权重）\n",
    "#total_accuracy = rf_accuracy + xgb_accuracy + lgb_accuracy\n",
    "\n",
    "# 计算加权平均\n",
    "#combined_importance = (rf_accuracy * rf_importance + \n",
    "#                       xgb_accuracy * xgb_importance + \n",
    "#                       lgb_accuracy * lgb_importance) / total_accuracy\n",
    "\n",
    "#方法四：排名转换为权重\n",
    "# 将特征重要性转换为排名（1为最高）\n",
    "# 1. 确保索引对齐，防止特征丢失\n",
    "all_features = rf_importance.index.union(xgb_importance.index).union(lgb_importance.index)\n",
    "rf_importance = rf_importance.reindex(all_features, fill_value=0)\n",
    "xgb_importance = xgb_importance.reindex(all_features, fill_value=0)\n",
    "lgb_importance = lgb_importance.reindex(all_features, fill_value=0)\n",
    "\n",
    "# 2. 计算每个模型的特征排名（数值越小越靠前）\n",
    "rf_rank = rf_importance.rank(ascending=False)\n",
    "xgb_rank = xgb_importance.rank(ascending=False)\n",
    "lgb_rank = lgb_importance.rank(ascending=False)\n",
    "\n",
    "# 3. 计算每个模型的反向排名权重：1 - (Rank - 1) / n\n",
    "n = len(all_features)\n",
    "reverse_rf_rank = 1 - (rf_rank - 1) / n\n",
    "reverse_xgb_rank = 1 - (xgb_rank - 1) / n\n",
    "reverse_lgb_rank = 1 - (lgb_rank - 1) / n\n",
    "\n",
    "# 4. 将反向排名权重乘以各模型的准确率\n",
    "weighted_rf = reverse_rf_rank * rf_accuracy\n",
    "weighted_xgb = reverse_xgb_rank * xgb_accuracy\n",
    "weighted_lgb = reverse_lgb_rank * lgb_accuracy\n",
    "\n",
    "# 5. 计算最终综合权重（取平均）\n",
    "combined_importance = (weighted_rf + weighted_xgb + weighted_lgb) / 3\n",
    "\n",
    "# 6. 将结果存入 DataFrame\n",
    "final_importance_df = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'RF_Rank': rf_rank.values,\n",
    "    'XGB_Rank': xgb_rank.values,\n",
    "    'LGB_Rank': lgb_rank.values,\n",
    "    'Reverse_RF_Rank': reverse_rf_rank.values,\n",
    "    'Reverse_XGB_Rank': reverse_xgb_rank.values,\n",
    "    'Reverse_LGB_Rank': reverse_lgb_rank.values,\n",
    "    'CombinedImportance': combined_importance.values\n",
    "})\n",
    "\n",
    "# 7. 输出最终结果\n",
    "print(final_importance_df)\n",
    "\n",
    "'''\n",
    "# 8.3 归一化到 0-1 之间\n",
    "final_importance = (combined_importance - combined_importance.min()) / (combined_importance.max() - combined_importance.min())\n",
    "\n",
    "# 8.3 将综合特征重要性保存到 DataFrame 并按权重排序\n",
    "final_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'RandomForest': rf_importance_norm.reindex(X.columns).values,\n",
    "    'XGBoost': xgb_importance_norm.reindex(X.columns).values,\n",
    "    'LightGBM': lgb_importance_norm.reindex(X.columns).values,\n",
    "    'CombinedImportance': final_importance.values\n",
    "}).sort_values(by='CombinedImportance', ascending=False)\n",
    "'''\n",
    "\n",
    "# 8.4 保存综合特征重要性到 CSV 文件\n",
    "final_importance_df.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_combined_feature_importance.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"综合特征重要性已保存至 'Well_B_combined_feature_importance.csv'\")\n",
    "\n",
    "# 8.5 绘制综合特征重要性条形图并保存（按降序排序）\n",
    "final_importance_df_sorted=final_importance_df.sort_values(by='CombinedImportance',ascending=False)\n",
    "plt.figure(figsize=(10, 8))\n",
    "# 使用 sns.barplot 绘制排序后的条形图\n",
    "sns.barplot(x='CombinedImportance', y='Feature', data=final_importance_df_sorted, palette='coolwarm')\n",
    "# 在每个条形上标注对应的数值\n",
    "for index, value in enumerate(final_importance_df_sorted['CombinedImportance']):\n",
    "    plt.text(value, index, f'{value:.2f}', va='center')\n",
    "# 设置图表标题和坐标轴标签\n",
    "plt.title(\"Combined feature importance\")\n",
    "plt.xlabel(\"Normalized importance score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "# 保存图像\n",
    "plt.tight_layout()\n",
    "plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/Combined_feature_importance.png', dpi=300)\n",
    "print(\"综合特征重要性图（排序后）已保存为 'Combined_feature_importance.png'\")\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb4d59",
   "metadata": {},
   "source": [
    "# 3、MLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96124fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 设置绘图参数 \n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 设置字体为加粗，符合SCI论文要求\n",
    "plt.rcParams['font.size'] = 12  # 设置整体字体大小为12，适合大多数论文\n",
    "plt.rcParams['font.weight'] = 'bold'  # 设置整体字体为加粗\n",
    "# 对于轴标签、标题、图例和刻度，可以做单独设置\n",
    "plt.rcParams['axes.titlesize'] = 14  # 轴标题更大\n",
    "plt.rcParams['axes.labelsize'] = 12   # 轴标签略大\n",
    "plt.rcParams['axes.titleweight'] = 'bold'  # 轴标题加粗\n",
    "plt.rcParams['axes.labelweight'] = 'bold'  # 轴标签加粗\n",
    "plt.rcParams['xtick.labelsize'] = 10   # x轴刻度标签稍大\n",
    "plt.rcParams['ytick.labelsize'] = 10   # y轴刻度标签稍大\n",
    "plt.rcParams['legend.fontsize'] = 10   # 图例字体更大\n",
    "plt.rcParams['legend.title_fontsize'] = 12  # 图例标题字体更大\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_IQR.csv')\n",
    "\n",
    "# 定义特征列表\n",
    "alpha_keys = ['WellDepth', 'DC', 'FormationPressureGradient', 'FormationRupturePressureGradient']\n",
    "beta_keys = ['WOB', 'RPM', 'TOR', 'PumpPressure', 'HookLoad', 'ROP']\n",
    "gamma_keys = ['Displacement', 'Density', 'ECD', 'OutletFlow', 'LagTime', 'TheoreticalMaximumDisplacement']\n",
    "\n",
    "# 特征标准化处理\n",
    "def normalize(column):\n",
    "    return (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "\n",
    "# 归一化特征\n",
    "df['WD_n'] = normalize('WellDepth')\n",
    "df['DC_n'] = normalize('DC')\n",
    "df['FoPG_n'] = normalize('FormationPressureGradient')\n",
    "df['FrPG_n'] = normalize('FormationRupturePressureGradient')\n",
    "df['WOB_n'] = normalize('WOB')\n",
    "df['RPM_n'] = normalize('RPM')\n",
    "df['TOR_n'] = normalize('TOR')\n",
    "df['PP_n'] = normalize('PumpPressure')\n",
    "df['HL_n'] = normalize('HookLoad')\n",
    "df['ROP_n'] = normalize('ROP')\n",
    "df['DIS_n'] = normalize('Displacement')\n",
    "df['OD_n'] = normalize('Density')\n",
    "df['ECD_n'] = normalize('ECD')\n",
    "df['FO_n'] = normalize('OutletFlow')\n",
    "df['LT_n'] = normalize('LagTime')\n",
    "df['TMD_n'] = normalize('TheoreticalMaximumDisplacement')\n",
    "\n",
    "# 定义标准化后列名的映射\n",
    "normalized_columns_mapping = {\n",
    "    'WellDepth': 'WD_n',\n",
    "    'DC': 'DC_n',\n",
    "    'FormationPressureGradient': 'FoPG_n',\n",
    "    'FormationRupturePressureGradient': 'FrPG_n',\n",
    "    'WOB': 'WOB_n',\n",
    "    'RPM': 'RPM_n',\n",
    "    'TOR': 'TOR_n',\n",
    "    'PumpPressure': 'PP_n',\n",
    "    'HookLoad': 'HL_n',\n",
    "    'ROP': 'ROP_n',\n",
    "    'Displacement': 'DIS_n',\n",
    "    'Density': 'OD_n',\n",
    "    'ECD': 'ECD_n',\n",
    "    'OutletFlow': 'FO_n',\n",
    "    'LagTime': 'LT_n',\n",
    "    'TheoreticalMaximumDisplacement': 'TMD_n',\n",
    "}\n",
    "\n",
    "# 数据中心化函数\n",
    "def center_data(df, keys):\n",
    "    return df[keys] - df[keys].mean()\n",
    "\n",
    "# 从 CSV 文件读取权重值，并对齐特征名称\n",
    "def load_weights(file_path, feature_keys):\n",
    "    weights_df = pd.read_csv(file_path)\n",
    "    weights_df.set_index('Feature', inplace=True)  # 确保特征名称为索引\n",
    "    # 提取与 feature_keys 对应的权重值\n",
    "    weights = weights_df.loc[feature_keys, 'CombinedImportance'].values\n",
    "    return weights\n",
    "\n",
    "def fit_logistic_regression(keys, normalized_columns_mapping, weights, file_path, C=5000):\n",
    "    # 准备数据并中心化\n",
    "    X = center_data(df, [normalized_columns_mapping[col] for col in keys])\n",
    "    y = df['LostCirculation']\n",
    "    # 对特征值应用权重\n",
    "    weights = load_weights(file_path, keys)\n",
    "    X_weighted = X * weights\n",
    "    # 拟合模型，不添加常数项\n",
    "    model = sm.Logit(y, X_weighted)\n",
    "    results = model.fit(disp=0)  # 关闭拟合过程中的输出\n",
    "    # 获取系数\n",
    "    params = results.params\n",
    "    # 获取大于0的最小系数\n",
    "    if (params > 0).any():  # 如果存在大于0的系数\n",
    "        min_positive_param = params[params > 0].min()\n",
    "    else:\n",
    "        # 如果所有系数都是≤0，使用某个默认值（比如选择系数中的最小值）\n",
    "        min_positive_param = params.min()\n",
    "\n",
    "    # 将小于等于0的系数替换为最小的大于0的系数\n",
    "    params = np.where(params <= 0, min_positive_param, params)\n",
    "    # 预测概率\n",
    "    predictions = results.predict(X_weighted)\n",
    "    \n",
    "    return predictions, params  # 返回预测值和调整后的系数\n",
    "\n",
    "file_path = 'E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_combined_feature_importance.csv'\n",
    "# 计算风险指数及其系数\n",
    "df['FormationRisk'], formation_params = fit_logistic_regression(alpha_keys, normalized_columns_mapping, None, file_path)\n",
    "df['DrillRisk'], drill_params = fit_logistic_regression(beta_keys, normalized_columns_mapping,None, file_path)\n",
    "df['FluidRisk'], fluid_params = fit_logistic_regression(gamma_keys, normalized_columns_mapping,None, file_path)\n",
    "\n",
    "# 将风险指数保留三位小数\n",
    "df['FormationRisk'] = round(df['FormationRisk'], 3)\n",
    "df['DrillRisk'] = round(df['DrillRisk'], 3)\n",
    "df['FluidRisk'] = round(df['FluidRisk'], 3)\n",
    "\n",
    "# 绘制拟合图并标注公式\n",
    "def plot_fitted_vs_actual(risk_name,predictions, actual, title, formula):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # 绘制真实值\n",
    "    plt.scatter(actual, actual, color='blue', label='LostCirculation', alpha=0.6)\n",
    "    # 绘制风险指数\n",
    "    plt.scatter(actual, predictions, color='red', label='RiskIndex', alpha=0.6)\n",
    "    # 添加拟合线\n",
    "    plt.plot([min(actual), max(actual)], [min(actual), max(actual)], color='green', linestyle='--', label='Perfect Fit')\n",
    "    \n",
    "    # 添加标题和标签\n",
    "    plt.title(title)\n",
    "    plt.xlabel('LostCirculation')\n",
    "    plt.ylabel('RiskIndex')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "\n",
    "    # 显示风险指数计算公式\n",
    "    plt.text(0.015, 0.9, formula, transform=plt.gca().transAxes,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/fit_{risk_name}.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# 定义每类风险的计算公式\n",
    "def create_formula(params, keys):\n",
    "    formula = \"Risk = \"\n",
    "    for i, key in enumerate(keys):\n",
    "        if i < len(params):  # 确保索引在范围内\n",
    "            if params[i] >= 0 and i > 0:  # 对于第一个系数不加加号\n",
    "                formula += f\" + {params[i]:.1f} * {key}\"\n",
    "            else:\n",
    "                formula += f\" {params[i]:.1f} * {key}\"\n",
    "    return formula\n",
    "\n",
    "formation_formula = create_formula(formation_params, alpha_keys)\n",
    "drill_formula = create_formula(drill_params, beta_keys)\n",
    "fluid_formula = create_formula(fluid_params, gamma_keys)\n",
    "\n",
    "# 绘制拟合图\n",
    "plot_fitted_vs_actual('FormationRisk',df['FormationRisk'], df['LostCirculation'], 'FormationRisk - LostCirculation', formation_formula)\n",
    "plot_fitted_vs_actual('DrillRisk',df['DrillRisk'], df['LostCirculation'], 'DrillRisk - LostCirculation', drill_formula)\n",
    "plot_fitted_vs_actual('FluidRisk',df['FluidRisk'], df['LostCirculation'], 'FluidRisk - LostCirculation', fluid_formula)\n",
    "\n",
    "# 计算混淆矩阵和ROC曲线的函数\n",
    "def evaluate_risk(risk_values, actual, risk_name):\n",
    "    threshold = 0.55  # 设定阈值\n",
    "    df[f'Predicted_{risk_name}'] = (risk_values >= threshold).astype(int)\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(actual, df[f'Predicted_{risk_name}'])\n",
    "    print(f\"Confusion Matrix for {risk_name}:\")\n",
    "    print(cm)\n",
    "\n",
    "    # 计算 AUC\n",
    "    auc = roc_auc_score(actual, risk_values)\n",
    "    print(f\"AUC for {risk_name}: {auc:.3f}\")\n",
    "\n",
    "    # 绘制 ROC 曲线\n",
    "    fpr, tpr, _ = roc_curve(actual, risk_values)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC of {risk_name} = {auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # 45度线\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve of {risk_name}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/roc_{risk_name}.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# 评估每类风险\n",
    "evaluate_risk(df['FormationRisk'], df['LostCirculation'], 'FormationRisk')\n",
    "evaluate_risk(df['DrillRisk'], df['LostCirculation'], 'DrillRisk')\n",
    "evaluate_risk(df['FluidRisk'], df['LostCirculation'], 'FluidRisk')\n",
    "\n",
    "#计算综合漏失风险指数\n",
    "# 读取特征权重数据\n",
    "weights_df = pd.read_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_combined_feature_importance.csv')\n",
    "weights_df.set_index('Feature', inplace=True)\n",
    "\n",
    "# 提取各类权重\n",
    "alpha_weights = weights_df.loc[alpha_keys, 'CombinedImportance']\n",
    "beta_weights = weights_df.loc[beta_keys, 'CombinedImportance']\n",
    "gamma_weights = weights_df.loc[gamma_keys, 'CombinedImportance']\n",
    "\n",
    "# 计算每个类别中各特征权重在整体特征权重中的占比\n",
    "total_weight = alpha_weights.sum() + beta_weights.sum() + gamma_weights.sum()\n",
    "formation_weight = alpha_weights.sum() / total_weight\n",
    "drill_weight = beta_weights.sum() / total_weight\n",
    "fluid_weight = gamma_weights.sum() / total_weight\n",
    "\n",
    "# 归一化各类权重\n",
    "alpha_weights = alpha_weights / alpha_weights.sum()\n",
    "beta_weights = beta_weights / beta_weights.sum()\n",
    "gamma_weights = gamma_weights / gamma_weights.sum()\n",
    "\n",
    "# 使用动态权重计算最终的漏失风险指数（MLR）\n",
    "# 这里的权重可以根据具体需求设定\n",
    "df['MLR'] = round(formation_weight * df['FormationRisk'] + drill_weight * df['DrillRisk'] + fluid_weight * df['FluidRisk'], 3)\n",
    "\n",
    "# 保存新的CSV文件\n",
    "df.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_MLR.csv', index=False, encoding='utf-8-sig')\n",
    "# 查看 MLR 与漏失情况的关系\n",
    "print(df[['MLR', 'LostCirculation']].describe())\n",
    "# 定义 MLR 列\n",
    "original_mlr_zero = df[df['LostCirculation'] == 0]['MLR']\n",
    "original_mlr_one = df[df['LostCirculation'] == 1]['MLR']\n",
    "\n",
    "# 可视化原始数据的漏失情况和漏失风险指数的对比分布\n",
    "def plot_original_mlr_distribution(original_zero, original_one, threshold,save_path):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))  # 使用1x2的子图布局\n",
    "\n",
    "    # 原始数据（正常循环类别）的分布图\n",
    "    sns.histplot(original_zero, bins=30, kde=True, color='#1f77b4', ax=axes[0])\n",
    "    axes[0].set_title('Normal Circulation (0)')\n",
    "    axes[0].set_xlabel('Machine-learning Lost-circulation Risk-index (MLR)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "\n",
    "    # 标注小于阈值的部分\n",
    "    axes[0].axvline(x=threshold, color='orange', linestyle='--', label='Threshold')\n",
    "    axes[0].fill_betweenx([0, axes[0].get_ylim()[1]], axes[0].get_xlim()[0], threshold, color='yellow', alpha=0.3)\n",
    "    axes[0].text(threshold, axes[0].get_ylim()[1] * 0.95, 'Below Threshold', color='black')\n",
    "\n",
    "    for p in axes[0].patches:\n",
    "        height = p.get_height()\n",
    "        if height > 0:\n",
    "            axes[0].text(p.get_x() + p.get_width() / 2., height, f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "    # 原始数据（漏失循环类别）的分布图\n",
    "    sns.histplot(original_one, bins=30, kde=True, color='red', ax=axes[1])\n",
    "    axes[1].set_title('Lost Circulation (1)')\n",
    "    axes[1].set_xlabel('Machine-learning Lost-circulation Risk-index (MLR)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "\n",
    "    # 标注大于阈值的部分\n",
    "    axes[1].axvline(x=threshold, color='orange', linestyle='--', label='Threshold')\n",
    "    axes[1].fill_betweenx([0, axes[1].get_ylim()[1]], threshold, axes[1].get_xlim()[1], color='yellow', alpha=0.3)\n",
    "    axes[1].text(threshold, axes[1].get_ylim()[1] * 0.95, 'Above Threshold', color='black')\n",
    "\n",
    "    for p in axes[1].patches:\n",
    "        height = p.get_height()\n",
    "        if height > 0:\n",
    "            axes[1].text(p.get_x() + p.get_width() / 2., height, f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# 调用绘制MLR-LC对比\n",
    "threshold_value = 0.55  # 设置阈值\n",
    "save_path='E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/comparison_mlr.png'\n",
    "plot_original_mlr_distribution(original_mlr_zero, original_mlr_one, threshold_value,save_path)\n",
    "\n",
    "def fit_logistic_model_and_plot(df, mrl_column, target_column, threshold=0.55):\n",
    "    # 添加常数项\n",
    "    X = sm.add_constant(df[mrl_column])  \n",
    "    y = df[target_column]\n",
    "    \n",
    "    # 拟合逻辑回归模型\n",
    "    model = sm.Logit(y, X)\n",
    "    results = model.fit(disp=0)  # 关闭拟合过程中的输出\n",
    "    \n",
    "    # 预测概率\n",
    "    df['MLR_fit'] = results.predict(X)\n",
    "    df.to_csv('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/data/Well_B_MLR_fit.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # 创建公式\n",
    "    intercept = results.params[0]\n",
    "    slope = results.params[1]\n",
    "    formula = f\"MLR_fit = {intercept:.1f} + {slope:.1f} * {mrl_column}\"\n",
    "\n",
    "    # 绘制拟合图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df[mrl_column], df[target_column], color='blue', label='LostCirculation', alpha=0.6)\n",
    "    plt.scatter(df[mrl_column], df['MLR_fit'], color='red', label='MLR_fit', alpha=0.6)\n",
    "    \n",
    "    # 添加标题和标签\n",
    "    plt.title('Logistic Fit')\n",
    "    plt.xlabel('MLR_fit')\n",
    "    plt.ylabel('Probability of Lost Circulation')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # 显示逻辑回归公式\n",
    "    plt.text(0.05, 0.9, formula, transform=plt.gca().transAxes,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/mlr_fit.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    df['predicted'] = (df['MLR_fit'] >= threshold).astype(int)\n",
    "    cm = confusion_matrix(df[target_column], df['predicted'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # 计算 AUC\n",
    "    auc = roc_auc_score(df[target_column], df['MLR_fit'])\n",
    "    print(f\"AUC: {auc:.3f}\")\n",
    "\n",
    "    # 绘制 ROC 曲线\n",
    "    fpr, tpr, _ = roc_curve(df[target_column], df['MLR_fit'])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC of MLR_fit = {auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # 45度线\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve of MLR_fit')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/mlr_fit_roc.png', dpi=300)\n",
    "    plt.show()\n",
    "    return results  # 返回拟合结果\n",
    "# 使用函数\n",
    "fit_logistic_model_and_plot(df, 'MLR', 'LostCirculation')\n",
    "\n",
    "# 定义 MLR_fit 列\n",
    "original_mlr_fit_zero = df[df['LostCirculation'] == 0]['MLR_fit']\n",
    "original_mlr_fit_one = df[df['LostCirculation'] == 1]['MLR_fit']\n",
    "# 调用绘制MLR_fit-LC对比\n",
    "threshold_value = 0.2  # 设置阈值\n",
    "save_path='E:/jupyter/lost_circulation/records/paper-bhyt/MLR/picture/comparison_mlr_fit.png'\n",
    "plot_original_mlr_distribution(original_mlr_fit_zero, original_mlr_fit_one, threshold_value,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a48b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
